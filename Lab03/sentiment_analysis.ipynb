{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nl\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import tweepy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de sentimento no twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando uma base de tweets em português já classificados como positivos ou negativos, um classificador do tipo Naive Bayes será treinado para depois ser aplicado em um conjunto de tweets específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Leitura e visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@caprichOreality Fica assim não miga &amp;lt;3 Tud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Parti me todo a descer a avenida de Gaia com o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amanhã é dia de dar um trato na palestra para ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@thankovsky @patorebaichado eu também tenho :)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ok. Sim. Aham. Tá. De boa. Vai lá. :) https://...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  sentiment\n",
       "0   1  @caprichOreality Fica assim não miga &lt;3 Tud...          1\n",
       "1   2  Parti me todo a descer a avenida de Gaia com o...          1\n",
       "2   3  Amanhã é dia de dar um trato na palestra para ...          1\n",
       "3   4  @thankovsky @patorebaichado eu também tenho :)...          1\n",
       "4   5  ok. Sim. Aham. Tá. De boa. Vai lá. :) https://...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('db.csv', encoding=\"utf-8\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           28172\n",
       "text         28172\n",
       "sentiment    28172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28172 tweets classificados como negativos (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           29924\n",
       "text         29924\n",
       "sentiment    29924\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29924 tweets classificados como positivos (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopwords(text):\n",
    "    stopwords = set(nl.corpus.stopwords.words('portuguese'))\n",
    "    words = [i for i in text.split() if not i in stopwords]\n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_chars(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
    "    text_with_no_special_chars = re.sub(\"\\s+\", \" \", text)\n",
    "    return text_with_no_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = clean_links(text)\n",
    "    text = clean_mentions(text)\n",
    "    text = clean_special_chars(text)\n",
    "    text = clean_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'text'] = clean_text(df.at[index, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fica assim miga lt tudo arranja deus quiser</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>parti todo descer avenida gaia skate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>amanhã é dia dar trato palestra thedevconf aju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>posso sentar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ok sim aham tá boa vai lá</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  sentiment\n",
       "0   1        fica assim miga lt tudo arranja deus quiser          1\n",
       "1   2               parti todo descer avenida gaia skate          1\n",
       "2   3  amanhã é dia dar trato palestra thedevconf aju...          1\n",
       "3   4                                       posso sentar          1\n",
       "4   5                          ok sim aham tá boa vai lá          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tweets de treinamento após a limpeza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a abordagem Bag of Words e o algoritmo Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Cria um vetor com cada uma das palavras do texto completo da base, \n",
    "depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então classificar/treinar o modelo\n",
    "'''\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "'''\n",
    "Ajusta o modelo, aprende o vocabulário, e transforma os dados de treinamento em vetores com frequêcia das palavras\n",
    "'''\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7437689341779125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia de 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando as medidas de validação do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74     29924\n",
      "          0       0.72      0.78      0.75     28172\n",
      "\n",
      "avg / total       0.75      0.74      0.74     58096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos = [1, 0]\n",
    "print(metrics.classification_report(classes, resultados, sentimentos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que:\n",
    "* precision = true positive / (true positive + false positive)\n",
    "* recall    = true positive / (true positive + false negative)\n",
    "* f1-score  = 2 x ((precision x recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo apresentou precisão de 0.77 ao classificar tweets positivos e 0.72 ao classificar tweets negativos, e uma precisão geral de 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito      0      1    All\n",
      "Real                        \n",
      "0        21957   6215  28172\n",
      "1         8671  21253  29924\n",
      "All      30628  27468  58096\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que:\n",
    "* Predito = O que o programa classificou como Negativo, Positivo e All\n",
    "* Real    = O que é de fato Negativo, Positivo e All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, o algoritmo classificou 21957 tweets realmente negativos como negativos, e 6215 tweets realmente negativos como positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação em dados da hashtag MasterChefBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador treinado será utilizado para analisar o sentimento de tweets contendo a hashtag #MasterChefBR. Os dados são baixados utilizando credenciais da api do Twitter. Como são muitos tweets e é necessário fazer uma classificação manual do sentimento, serão escolhidos e classificados 50 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "####input your credentials here\n",
    "consumer_key = 'X1iKxRO9vW3VBdfdQrBxCKneA'\n",
    "consumer_secret = 'J73REOsIZoWFnjPC0VZtF3CWRTBrfx0l4v85TvAUC8tBIJ1PwA'\n",
    "access_token = '191642356-02GI0AIT8ddbmWuDOF6twcMU0sRzyoiyjiX6bvtZ'\n",
    "access_token_secret = 'QWMtL7jSYMgR1Rk5gQf8pI09cRqchb2jE7MUcFYXuatJD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open/Create a file to append data\n",
    "csvFile = open('mc.csv', 'w')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow([\"Data\", \"Tweet\"])\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#MasterChefBR -RT\",count=100,\n",
    "                           lang=\"pt\",\n",
    "                           since=\"2018-01-01\").items():\n",
    "    text = clean_text(tweet.text)\n",
    "    csvWriter.writerow([tweet.created_at, text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-31 02:08:33</td>\n",
       "      <td>bora lá hugo pega troféu masterchefbr ganhahugo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-31 02:02:44</td>\n",
       "      <td>segunda feira 23h jovem pensa começa final mas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-31 01:52:33</td>\n",
       "      <td>embuste ganhar amanhã vou ficar putassa master...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-31 01:52:10</td>\n",
       "      <td>hugo ganhar nada importa doq opinião masterchefbr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-31 01:42:48</td>\n",
       "      <td>maria antônia diabo suporta masterchefbr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Data                                              Tweet  \\\n",
       "0  2018-07-31 02:08:33    bora lá hugo pega troféu masterchefbr ganhahugo   \n",
       "1  2018-07-31 02:02:44  segunda feira 23h jovem pensa começa final mas...   \n",
       "2  2018-07-31 01:52:33  embuste ganhar amanhã vou ficar putassa master...   \n",
       "3  2018-07-31 01:52:10  hugo ganhar nada importa doq opinião masterchefbr   \n",
       "4  2018-07-31 01:42:48           maria antônia diabo suporta masterchefbr   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"mc.csv\", encoding=\"utf-8\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tweets já selecionados e classificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = []\n",
    "for index, row in tweets.iterrows():\n",
    "    testes.append(tweets.at[index, 'Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_teste = tweets[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_testes = vectorizer.transform(testes)\n",
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_teste = cross_val_predict(modelo, freq_testes, classes_teste, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes_teste, resultados_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia de 0.7, apenas 0.04 menor que a do treinamento, devido ao número de tweets ser bem menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.54      0.63        24\n",
      "          1       0.67      0.85      0.75        26\n",
      "\n",
      "avg / total       0.71      0.70      0.69        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos = [0, 1]\n",
    "print(metrics.classification_report(classes_teste, resultados_teste, sentimentos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo apresentou precisão de 0.67 ao classificar tweets positivos e 0.76 ao classificar tweets negativos, e uma precisão geral de 0.71. A precisão foi menor que a do treinamento, exceto na classificação de tweets negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   0   1  All\n",
      "Real                \n",
      "0        13  11   24\n",
      "1         4  22   26\n",
      "All      17  33   50\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(classes_teste, resultados_teste, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, o algoritmo classificou 13 tweets realmente negativos como negativos, e 11 tweets realmente negativos como positivos. Para o caso dos tweets realmente positivos o algoritmo apresentou melhor predição, de 22 tweets positivos, quando o total é de 26."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
