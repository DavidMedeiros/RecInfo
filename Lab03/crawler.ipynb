{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####input your credentials here\n",
    "consumer_key = 'X1iKxRO9vW3VBdfdQrBxCKneA'\n",
    "consumer_secret = 'J73REOsIZoWFnjPC0VZtF3CWRTBrfx0l4v85TvAUC8tBIJ1PwA'\n",
    "access_token = '191642356-02GI0AIT8ddbmWuDOF6twcMU0sRzyoiyjiX6bvtZ'\n",
    "access_token_secret = 'QWMtL7jSYMgR1Rk5gQf8pI09cRqchb2jE7MUcFYXuatJD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    return \" \".join([word for word in text.split()\n",
    "                    if 'http' not in word and '@' not in word and '<' not in word and '#' not in word and '\\\\xf' not in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    words = [i for i in text.split() if not i in stopwords]\n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
    "    text_with_no_special_chars = re.sub(\"\\s+\", \" \", text)\n",
    "    return text_with_no_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        words.append(stemmer.stem(word))\n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_links(text)\n",
    "    text = remove_mentions(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_special_chars(text)\n",
    "    #text = stemming(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ainda bem que acabou semana passada pq aÃ­ TerÃ§a Feira ficarei na tag\n",
      "Rita e major finalistas morais do\n",
      "vem tÃ´ preparada\n",
      "A MAIORIA TORCENDO PRO HUGO EU TO PIRANDO MEU FAV TEM QUE GANHARRRRR\n",
      "RAINHA! FADA! ANJO!\n",
      "Apesar do Hugo ser bem foda, minha torcida Ã© pra Maria AntÃ´nia.\n",
      "TerÃ§a feira eh dia de caÃ§a Ã s bruxas....to torcendo pelo paladino pra levar o trofÃ©u pra casa junto comâ€¦\n",
      "eu sou muito masterchef jÃ¡ Ã© dele mesmo se ganhar ou nao\n",
      "Conquistar um lugar na Grande Final, exige muito sacrifÃ­cio na cozinha e forÃ§a de vontade! TerÃ§â€¦\n",
      "Pudim sem forno ðŸ˜Ž\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\U0001f60e' in position 36: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-932404a704e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                            since=\"2018-01-01\").items():\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcsvWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\U0001f60e' in position 36: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Open/Create a file to append data\n",
    "csvFile = open('a.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow([\"Data\", \"Tweet\"])\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#MasterChefBR -RT\",count=100,\n",
    "                           lang=\"pt\",\n",
    "                           since=\"2018-01-01\").items():\n",
    "    print (processing(tweet.text))\n",
    "    csvWriter.writerow([tweet.created_at, processing(tweet.text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"mc.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-29 19:02:15</td>\n",
       "      <td>b'Voc\\xc3\\xaa consegue acertar todas as pergun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-29 18:56:42</td>\n",
       "      <td>b'@masterchefbr @KnorrBrasil @BandTV  fica de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-29 18:18:52</td>\n",
       "      <td>b'J\\xc3\\xa1 ganhou meu amor #MasterChefBR #Gan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-29 18:16:14</td>\n",
       "      <td>b'@ChefLeoSantos opsss... nem acredito que n\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-29 18:14:44</td>\n",
       "      <td>b'@MAntoniaMChef eu n\\xc3\\xa3o tenho nada cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Data                                              Tweet\n",
       "0  2018-07-29 19:02:15  b'Voc\\xc3\\xaa consegue acertar todas as pergun...\n",
       "1  2018-07-29 18:56:42  b'@masterchefbr @KnorrBrasil @BandTV  fica de ...\n",
       "2  2018-07-29 18:18:52  b'J\\xc3\\xa1 ganhou meu amor #MasterChefBR #Gan...\n",
       "3  2018-07-29 18:16:14  b'@ChefLeoSantos opsss... nem acredito que n\\x...\n",
       "4  2018-07-29 18:14:44  b'@MAntoniaMChef eu n\\xc3\\xa3o tenho nada cont..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove URLs and twitter handles\n",
    "for i in range(len(tweets['Tweet'])):\n",
    "    tweets['Tweet'][i] = \" \".join([word for word in tweets['Tweet'][i].split()\n",
    "                                if 'http' not in word and '@' not in word and '<' not in word and '#' not in word and '\\\\xf' not in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'S\\\\xc3\\\\xb3 pra n\\\\xc3\\\\xa3o esquecer\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"Tweet\"][28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SÃ³ pra nÃ£o esquecer ðŸ–¤ #MasterChefBR https://t.co/L625rPMuuh'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = b'S\\xc3\\xb3 pra n\\xc3\\xa3o esquecer \\xf0\\x9f\\x96\\xa4 #MasterChefBR https://t.co/L625rPMuuh'\n",
    "s.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
