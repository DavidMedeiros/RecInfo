{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from queue import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noticias = pd.read_csv('estadao_noticias_eleicao.csv')\n",
    "noticias.set_index(\"idNoticia\", inplace=True)\n",
    "\n",
    "gabarito = pd.read_csv('gabarito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lê e separa as palavras de um texto de determinada notícia, para adicionar ou atualizar o índice 'palavra' do dicionário\n",
    "def cataloga_palavras(dicionario, texto, idNoticia):\n",
    "    palavras = nltk.word_tokenize(texto)\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        palavra = palavra.lower()   #o algoritmo não é case-sensitive\n",
    "        if palavra in dicionario:\n",
    "            if idNoticia in dicionario[palavra]:\n",
    "                dicionario[palavra][idNoticia] += 1\n",
    "            else:\n",
    "                dicionario[palavra][idNoticia] = 1\n",
    "        else:\n",
    "            dicionario[palavra] = {}\n",
    "            dicionario[palavra][idNoticia] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retorna os ids de notícias que possuem aquela palavra\n",
    "def indice_invertido(palavra):\n",
    "    return dicionario[palavra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicionario = {}\n",
    "\n",
    "#Cataloga as palavras de todas as notícias da tabela\n",
    "for index, row in noticias.iterrows():\n",
    "    \n",
    "    #Tratamento de valores NaN na tabela\n",
    "    titulo = '' if str(row['titulo']) == 'nan' else str(row['titulo'])\n",
    "    subTitulo = '' if str(row['subTitulo']) == 'nan' else str(row['subTitulo'])\n",
    "    conteudo = '' if str(row['conteudo']) == 'nan' else str(row['conteudo'])\n",
    "    \n",
    "    texto = titulo + \" \" + subTitulo + \" \" + conteudo\n",
    "    \n",
    "    cataloga_palavras(dicionario, texto, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calcula IDF para um indice invertido\n",
    "def calcula_idf(indice):\n",
    "    m = noticias.shape[0]\n",
    "    k = len(indice)\n",
    "    return np.log((m + 1)/k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Busca binaria, retorna os 5 documentos mais relevantes em que os termos da consulta estão presentes.\n",
    "def binaria(consulta):\n",
    "    termos = consulta.split()\n",
    "    buscas = PriorityQueue()\n",
    "    for termo in termos:\n",
    "        termo = termo.lower()\n",
    "        indice = indice_invertido(termo)\n",
    "        buscas.put((len(indice), indice.keys()))  #A fila de prioridades armazena a quantidade de documentos em que\n",
    "                                                  #cada termo aparece e os índices desses documentos\n",
    "    if len(termos) == 1:\n",
    "        return buscas.get()[1]\n",
    "    while buscas.qsize()> 1:\n",
    "        parte1 = set(buscas.get()[1])\n",
    "        parte2 = set(buscas.get()[1])\n",
    "        parcial = parte1.intersection(parte2)  #Interseção de dois itens da fila, até que só exista um elemento\n",
    "        size = len(parcial)\n",
    "        buscas.put((size, list(parcial)))\n",
    "    return buscas.get()[1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect_tf(s1, s2):\n",
    "    result = {}\n",
    "    docs = set(s1.keys()).intersection(set(s2.keys()))\n",
    "    for key in docs:\n",
    "        result[key] = s1[key] + s2[key]  #Soma do tf no documento\n",
    "    return result\n",
    "\n",
    "def tf(consulta):\n",
    "    termos = consulta.split()\n",
    "    buscas = PriorityQueue()\n",
    "    for termo in termos:\n",
    "        termo = termo.lower()\n",
    "        indice = indice_invertido(termo)\n",
    "        buscas.put((len(indice), indice))  #A fila de prioridades armazena a quantidade de documentos em que\n",
    "                                           #cada termo aparece e o índice invertido de cada termo\n",
    "    if len(termos) == 1:\n",
    "        return buscas.get()[1]\n",
    "    while buscas.qsize()> 1:\n",
    "        parte1 = buscas.get()[1]\n",
    "        parte2 = buscas.get()[1]\n",
    "        parcial = intersect_tf(parte1, parte2)  #Interseção de dois itens da fila, até que só exista um elemento\n",
    "        size = len(parcial)\n",
    "        buscas.put((size, parcial))\n",
    "    return ordena_top5(buscas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect_tfidf(s1, s2):\n",
    "    result = {}\n",
    "    docs = set(s1.keys()).intersection(set(s2.keys()))\n",
    "    for key in docs:\n",
    "        result[key] = s1[key] * calcula_idf(s1) + s2[key] * calcula_idf(s2)  #Soma do idf no documento\n",
    "    return result\n",
    "\n",
    "def tfidf(consulta):\n",
    "    termos = consulta.split()\n",
    "    buscas = PriorityQueue()\n",
    "    for termo in termos:\n",
    "        termo = termo.lower()\n",
    "        indice = indice_invertido(termo)\n",
    "        buscas.put((len(indice), indice))  #A fila de prioridades armazena a quantidade de documentos em que\n",
    "                                           #cada termo aparece e o índice invertido de cada termo\n",
    "    if len(termos) == 1:\n",
    "        return buscas.get()[1]\n",
    "    while buscas.qsize()> 1:\n",
    "        parte1 = buscas.get()[1]\n",
    "        parte2 = buscas.get()[1]\n",
    "        parcial = intersect_tfidf(parte1, parte2)  #Interseção de dois itens da fila, até que só exista um elemento\n",
    "        size = len(parcial)\n",
    "        buscas.put((size, parcial))\n",
    "    return ordena_top5(buscas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect_bm25(s1, s2):\n",
    "    k = np.random.uniform(low=1.2, high=2)\n",
    "    result = {}\n",
    "    docs = set(s1.keys()).intersection(set(s2.keys()))\n",
    "    for key in docs:\n",
    "        #Cálculo do bm25\n",
    "        result[key] = (calcula_idf(s1) * s1[key] * (k + 1) / (s1[key] + k)) + (calcula_idf(s2) * s2[key] * (k + 1) / (s2[key] + k))\n",
    "    return result\n",
    "\n",
    "def bm25(consulta):\n",
    "    termos = consulta.split()\n",
    "    buscas = PriorityQueue()\n",
    "    for termo in termos:\n",
    "        termo = termo.lower()\n",
    "        indice = indice_invertido(termo)\n",
    "        buscas.put((len(indice), indice))  #A fila de prioridades armazena a quantidade de documentos em que\n",
    "                                           #cada termo aparece e o índice invertido de cada termo\n",
    "    if len(termos) == 1:\n",
    "        return buscas.get()[1]\n",
    "    while buscas.qsize()> 1:\n",
    "        parte1 = buscas.get()[1]\n",
    "        parte2 = buscas.get()[1]\n",
    "        parcial = intersect_bm25(parte1, parte2)  #Interseção de dois itens da fila, até que só exista um elemento\n",
    "        size = len(parcial)\n",
    "        buscas.put((size, parcial))\n",
    "    return ordena_top5(buscas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ordena_top5(buscas):\n",
    "    sorted_result = sorted(buscas.get()[1].items(), key=lambda x: -x[1])  #Documentos em ordem decrescente de idf\n",
    "    top5 = sorted_result[0:5]  #Apenas os 5 primeiros resultados\n",
    "    top5 = [x[0] for x in top5]  #Listar pelo id do documento\n",
    "    return top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_busca</th>\n",
       "      <th>busca_binaria</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>segundo turno</td>\n",
       "      <td>[2048, 1, 2049, 2050, 4096]</td>\n",
       "      <td>[2744, 7, 2112, 7672, 2388]</td>\n",
       "      <td>[2744, 2112, 7672, 1235, 2388]</td>\n",
       "      <td>[2744, 2112, 7672, 2388, 2178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lava jato</td>\n",
       "      <td>[3, 13, 15, 27, 6177]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projeto de lei</td>\n",
       "      <td>[3584, 6145, 8194, 8706, 6660]</td>\n",
       "      <td>[7, 3942, 7017, 1250, 6942]</td>\n",
       "      <td>[7017, 2853, 2232, 3171, 6461]</td>\n",
       "      <td>[2853, 3171, 2232, 6699, 6461]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compra de voto</td>\n",
       "      <td>[7424, 2178, 6531, 5122, 2311]</td>\n",
       "      <td>[3942, 7017, 5129, 2047, 748]</td>\n",
       "      <td>[7343, 2047, 7293, 6791, 7017]</td>\n",
       "      <td>[2200, 2047, 2178, 7343, 7293]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minstério público</td>\n",
       "      <td>[8194, 7, 4104, 8201, 4109]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           str_busca                   busca_binaria  \\\n",
       "0      segundo turno     [2048, 1, 2049, 2050, 4096]   \n",
       "1          lava jato           [3, 13, 15, 27, 6177]   \n",
       "2     projeto de lei  [3584, 6145, 8194, 8706, 6660]   \n",
       "3     compra de voto  [7424, 2178, 6531, 5122, 2311]   \n",
       "4  minstério público     [8194, 7, 4104, 8201, 4109]   \n",
       "\n",
       "                               tf                           tfidf  \\\n",
       "0     [2744, 7, 2112, 7672, 2388]  [2744, 2112, 7672, 1235, 2388]   \n",
       "1      [163, 353, 2807, 127, 359]      [163, 353, 2807, 127, 359]   \n",
       "2     [7, 3942, 7017, 1250, 6942]  [7017, 2853, 2232, 3171, 6461]   \n",
       "3   [3942, 7017, 5129, 2047, 748]  [7343, 2047, 7293, 6791, 7017]   \n",
       "4  [6798, 8018, 6244, 6965, 6550]  [6798, 8018, 6244, 6965, 6550]   \n",
       "\n",
       "                             bm25  \n",
       "0  [2744, 2112, 7672, 2388, 2178]  \n",
       "1      [163, 353, 2807, 127, 359]  \n",
       "2  [2853, 3171, 2232, 6699, 6461]  \n",
       "3  [2200, 2047, 2178, 7343, 7293]  \n",
       "4  [6798, 8018, 6244, 6965, 6550]  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'str_busca': [\"segundo turno\", \"lava jato\", \"projeto de lei\", \"compra de voto\", \"minstério público\"],\n",
    "     'busca_binaria': [binaria(\"segundo turno\"), binaria(\"lava jato\"), binaria(\"projeto de lei\"), binaria(\"compra de voto\"), binaria(\"ministério público\")], \n",
    "     'tf': [tf(\"segundo turno\"), tf(\"lava jato\"), tf(\"projeto de lei\"), tf(\"compra de voto\"), tf(\"ministério público\")],\n",
    "     'tfidf': [tfidf(\"segundo turno\"), tfidf(\"lava jato\"), tfidf(\"projeto de lei\"), tfidf(\"compra de voto\"), tfidf(\"ministério público\")],\n",
    "     'bm25': [bm25(\"segundo turno\"), bm25(\"lava jato\"), bm25(\"projeto de lei\"), bm25(\"compra de voto\"), bm25(\"ministério público\")]}\n",
    "resposta = pd.DataFrame(data=d)\n",
    "resposta = resposta[['str_busca', 'busca_binaria', 'tf', 'tfidf', 'bm25']]\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratando o formato das colunas\n",
    "def get_expected_results(df):   \n",
    "    expected_answers = []\n",
    "    for query_result in df:        \n",
    "        as_str = re.sub('[,\\[\\]]', '', query_result)\n",
    "        as_list = as_str.split(\" \")\n",
    "        list_of_int = list(map(int, as_list))\n",
    "        expected_answers.append(list_of_int)\n",
    "    return expected_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.608666666667\n",
      "0.778\n",
      "0.0\n",
      "0.048\n",
      "0.088\n",
      "0.168\n"
     ]
    }
   ],
   "source": [
    "print(mapk(get_expected_results(gabarito.busca_binaria), resposta.busca_binaria, k=5))\n",
    "print(mapk(get_expected_results(gabarito.tf), resposta.tf, k=5))\n",
    "print(mapk(get_expected_results(gabarito.tfidf), resposta.tf, k=5))\n",
    "print(mapk(get_expected_results(gabarito.bm25), resposta.bm25, k=5))\n",
    "\n",
    "print(mapk(get_expected_results(gabarito.google), resposta.busca_binaria, k=5))\n",
    "print(mapk(get_expected_results(gabarito.google), resposta.tf, k=5))\n",
    "print(mapk(get_expected_results(gabarito.google), resposta.tfidf, k=5))\n",
    "print(mapk(get_expected_results(gabarito.google), resposta.bm25, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação ao gabarito, os modelos mais precisos foram a Busca Binária e TF.\n",
    "As comparações com os resultados do google tiveram precisão baixa, como esperado. Neste caso, o modelo BM25 obteve melhores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
